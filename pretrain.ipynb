{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing import image as image_utils\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(220,293, 3))\n",
    "#include top是要不要fully connection\n",
    "model=keras.applications.xception.Xception(include_top=False, weights='imagenet',\n",
    "                                    input_tensor=input_tensor,\n",
    "                                    pooling=None, classes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jason/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  after removing the cwd from sys.path.\n",
      "/home/jason/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.2)`\n",
      "  \"\"\"\n",
      "/home/jason/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  \n",
      "/home/jason/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=15)`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(output_dim=128, activation='relu')(x)\n",
    "x=Dropout(p=0.2)(x)\n",
    "x = Dense(output_dim=128, activation='relu')(x)\n",
    "\n",
    "\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "\n",
    "\n",
    "predictions = Dense(output_dim=15,activation='softmax')(x)\n",
    "model = Model(inputs=model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#如果想鎖住本來model裡面的權重\n",
    "'''for layer in model.layers:\n",
    "    layer.trainable = False''' \n",
    "for layer in model.layers[:120]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[120:139]:\n",
    "   layer.trainable = True\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "if not os.path.isdir(os.getcwd()):\n",
    "    os.makedirs(os.getcwd())\n",
    "model_path = os.path.join(os.getcwd(),'cat_dog_autosave_classification.h5')\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "#validation_loss訓練超過五次都沒進步，主要是避免overfitting\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   rotation_range=30,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   vertical_flip=False)\n",
    "#width_shift_range=0.1,height_shift_range=0.1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2985 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('/home/jason/Desktop/where_am_i/train',\n",
    "                                                 target_size = (220, 293),\n",
    "                                                 batch_size = 32,#可以改\n",
    "                                                 class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "檔案： test.ipynb\n",
      "檔案： tensorflow.ipynb\n",
      "檔案： keras2_answer.csv\n",
      "檔案： whereami-dl-tensorflow.ipynb\n",
      "檔案： 期中.ipynb\n",
      "檔案： testset_img_list.csv\n",
      "檔案： train_img_list.csv\n",
      "目錄： .ipynb_checkpoints\n",
      "目錄： aia-picture-classification1\n",
      "檔案： .DS_Store\n",
      "檔案： train_img_list_label.csv\n",
      "檔案： mid_term_mapping.txt\n",
      "檔案： the_answer.csv\n",
      "檔案： img-submission.csv\n",
      "檔案： keras.ipynb\n",
      "目錄： testset\n",
      "目錄： train\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, isdir, join\n",
    "\n",
    "# 指定要列出所有檔案的目錄\n",
    "mypath = \"/home/jason/Desktop/where_am_i\"\n",
    "\n",
    "# 取得所有檔案與子目錄名稱\n",
    "files = listdir(mypath)\n",
    "\n",
    "# 以迴圈處理\n",
    "for f in files:\n",
    "  # 產生檔案的絕對路徑\n",
    "  fullpath = join(mypath, f)\n",
    "  # 判斷 fullpath 是檔案還是目錄\n",
    "  if isfile(fullpath):\n",
    "    print(\"檔案：\", f)\n",
    "  elif isdir(fullpath):\n",
    "    print(\"目錄：\", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jason/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/jason/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=93, epochs=30)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "93/93 [==============================] - 30s 320ms/step - loss: 0.9973 - acc: 0.6856\n",
      "Epoch 2/30\n",
      "93/93 [==============================] - 28s 306ms/step - loss: 0.4809 - acc: 0.8422\n",
      "Epoch 3/30\n",
      "93/93 [==============================] - 28s 305ms/step - loss: 0.3992 - acc: 0.8686\n",
      "Epoch 4/30\n",
      "93/93 [==============================] - 29s 309ms/step - loss: 0.3406 - acc: 0.8953\n",
      "Epoch 5/30\n",
      "93/93 [==============================] - 29s 310ms/step - loss: 0.3358 - acc: 0.8953\n",
      "Epoch 6/30\n",
      "93/93 [==============================] - 29s 310ms/step - loss: 0.3265 - acc: 0.8968\n",
      "Epoch 7/30\n",
      "93/93 [==============================] - 29s 311ms/step - loss: 0.2501 - acc: 0.9240\n",
      "Epoch 8/30\n",
      "93/93 [==============================] - 29s 311ms/step - loss: 0.2399 - acc: 0.9235\n",
      "Epoch 9/30\n",
      "93/93 [==============================] - 29s 307ms/step - loss: 0.2159 - acc: 0.9326\n",
      "Epoch 10/30\n",
      "93/93 [==============================] - 29s 307ms/step - loss: 0.2129 - acc: 0.9363\n",
      "Epoch 11/30\n",
      "93/93 [==============================] - 29s 308ms/step - loss: 0.2010 - acc: 0.9427\n",
      "Epoch 12/30\n",
      "93/93 [==============================] - 29s 309ms/step - loss: 0.2163 - acc: 0.9361\n",
      "Epoch 13/30\n",
      "93/93 [==============================] - 29s 309ms/step - loss: 0.1628 - acc: 0.9489\n",
      "Epoch 14/30\n",
      "93/93 [==============================] - 29s 312ms/step - loss: 0.1766 - acc: 0.9496\n",
      "Epoch 15/30\n",
      "93/93 [==============================] - 29s 309ms/step - loss: 0.1372 - acc: 0.9563\n",
      "Epoch 16/30\n",
      "93/93 [==============================] - 29s 308ms/step - loss: 0.1335 - acc: 0.9600\n",
      "Epoch 17/30\n",
      "93/93 [==============================] - 30s 319ms/step - loss: 0.1316 - acc: 0.9593\n",
      "Epoch 18/30\n",
      "93/93 [==============================] - 29s 308ms/step - loss: 0.1520 - acc: 0.9507\n",
      "Epoch 19/30\n",
      "93/93 [==============================] - 28s 306ms/step - loss: 0.1419 - acc: 0.9590\n",
      "Epoch 20/30\n",
      "93/93 [==============================] - 29s 315ms/step - loss: 0.1274 - acc: 0.9613\n",
      "Epoch 21/30\n",
      "93/93 [==============================] - 29s 314ms/step - loss: 0.1217 - acc: 0.9612\n",
      "Epoch 22/30\n",
      "93/93 [==============================] - 29s 308ms/step - loss: 0.1201 - acc: 0.9632\n",
      "Epoch 23/30\n",
      "93/93 [==============================] - 29s 315ms/step - loss: 0.1022 - acc: 0.9664\n",
      "Epoch 24/30\n",
      "93/93 [==============================] - 29s 307ms/step - loss: 0.0828 - acc: 0.9743\n",
      "Epoch 25/30\n",
      "93/93 [==============================] - 29s 309ms/step - loss: 0.1184 - acc: 0.9644\n",
      "Epoch 26/30\n",
      "93/93 [==============================] - 28s 305ms/step - loss: 0.0971 - acc: 0.9682\n",
      "Epoch 27/30\n",
      "93/93 [==============================] - 30s 321ms/step - loss: 0.1146 - acc: 0.9689\n",
      "Epoch 28/30\n",
      "93/93 [==============================] - 29s 308ms/step - loss: 0.0830 - acc: 0.9756\n",
      "Epoch 29/30\n",
      "93/93 [==============================] - 29s 309ms/step - loss: 0.0852 - acc: 0.9738\n",
      "Epoch 30/30\n",
      "93/93 [==============================] - 30s 326ms/step - loss: 0.0864 - acc: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efd1090bf98>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(training_set,\n",
    "                         samples_per_epoch = 2985,\n",
    "                         nb_epoch = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-4d16553960c8>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-4d16553960c8>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    street 13\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#預測\n",
    "street 13\n",
    "kitchen 8\n",
    "mountain 10\n",
    "insidecity 7\n",
    "livingroom 9\n",
    "opencountry 11\n",
    "CALsuburb 0\n",
    "PARoffice 1\n",
    "highway 5\n",
    "coast 3\n",
    "bedroom 2\n",
    "tallbuilding 14\n",
    "industrial 6\n",
    "forest 4\n",
    "store 12\n",
    "\n",
    "#真實\n",
    "CALsuburb, 9\n",
    "PARoffice, 7\n",
    "bedroom, 12\n",
    "coast, 10\n",
    "forest, 4\n",
    "highway, 14\n",
    "industrial, 2\n",
    "insidecity, 3\n",
    "kitchen, 0\n",
    "livingroom, 5\n",
    "mountain, 8\n",
    "opencountry, 6\n",
    "store, 11\n",
    "street, 1\n",
    "tallbuilding, 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "All_picture=[]\n",
    "path =r'/home/jason/Desktop/where_am_i/testset' # use your path\n",
    "allFiles = glob.glob(path + \"/*.jpg\")\n",
    "test_=[]\n",
    "for picture in allFiles:\n",
    "    test_image_1 = image_utils.load_img(picture, target_size=(220, 293))\n",
    "    test_image_1 = image_utils.img_to_array(test_image_1)\n",
    "    test_image_1 = np.expand_dims(test_image_1, axis=0)\n",
    "    test_image_1 =test_image_1 /255\n",
    "    new=model.predict(test_image_1)\n",
    "    new=np.argmax(new)\n",
    "    test_.append(new)\n",
    "answer=[]\n",
    "for x in test_:\n",
    "    if x==13:\n",
    "        x=1\n",
    "    elif x==8:\n",
    "        x=0\n",
    "    elif x==10:\n",
    "        x=8\n",
    "    elif x==7:\n",
    "        x=3\n",
    "    elif x==9:\n",
    "        x=5\n",
    "    elif x==11:\n",
    "        x=6\n",
    "    elif x==0:\n",
    "        x=9\n",
    "    elif x==1:\n",
    "        x=7\n",
    "    elif x==5:\n",
    "        x=14\n",
    "    elif x==3:\n",
    "        x=10\n",
    "    elif x==2:\n",
    "        x=12\n",
    "    elif x==14:\n",
    "        x=13\n",
    "    elif x==6:\n",
    "        x=2\n",
    "    elif x==4:\n",
    "        x=4\n",
    "    elif x==12:\n",
    "        x=11\n",
    "    answer.append(x)\n",
    "len(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "result_csv=pd.read_csv('img-submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c117693e1cf24a5232090d1548cb11d4e5ea0df65680c4...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96baacc2e97886a998807ce197574821a6dc83c227c746...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f9bd26db23eb9b544ca78be79b11b4d1259e802885861d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b42bcd8e6645fcc2ac40ee44b7dc8d74a77081d0aea7a1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5bc53cef9168882f0ff67a81b3e7269f62b7fd5343d06d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  class\n",
       "0  c117693e1cf24a5232090d1548cb11d4e5ea0df65680c4...      1\n",
       "1  96baacc2e97886a998807ce197574821a6dc83c227c746...      1\n",
       "2  f9bd26db23eb9b544ca78be79b11b4d1259e802885861d...      1\n",
       "3  b42bcd8e6645fcc2ac40ee44b7dc8d74a77081d0aea7a1...      1\n",
       "4  5bc53cef9168882f0ff67a81b3e7269f62b7fd5343d06d...      1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_columns=[]\n",
    "for x in allFiles:\n",
    "    hi=x.split('/')[6].split('.')[0]\n",
    "    first_columns.append(hi)\n",
    "result_csv['id']=first_columns \n",
    "result_csv['class']=answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0b6ee55106786db0eacf7cab333b3dbd20f9f0e85a0859...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3663fc4e1a0119ab3aa8d53e12ce2007f2a35aa0b1f9f3...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e7a0975f76e6e9fe820a07f47080d264b960e79605890b...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7bae1d6cec7feb538eb7ff985191cacf96e122eaf4be21...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4a46ae60618eb7bb43d7c227d2c606927549e5e09c0e32...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  class\n",
       "0  0b6ee55106786db0eacf7cab333b3dbd20f9f0e85a0859...      6\n",
       "1  3663fc4e1a0119ab3aa8d53e12ce2007f2a35aa0b1f9f3...      6\n",
       "2  e7a0975f76e6e9fe820a07f47080d264b960e79605890b...      8\n",
       "3  7bae1d6cec7feb538eb7ff985191cacf96e122eaf4be21...     14\n",
       "4  4a46ae60618eb7bb43d7c227d2c606927549e5e09c0e32...     12"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import os \n",
    "os.chdir('/home/jovyan')\n",
    "result_csv=pd.read_csv('img-submission.csv')\n",
    "result_csv['class']=answer'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_csv.to_csv('keras3_answer.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image as image_utils\n",
    "test_answer=[]\n",
    "result_csv=pd.read_csv('img-submission.csv')\n",
    "for data_real in result_csv['id']:\n",
    "    test_answer.append('//data/examples/may_the_4_be_with_u/where_am_i/testset/'+data_real+'.jpg')\n",
    "test_=[]\n",
    "for picture in test_answer:\n",
    "    test_image_1 = image_utils.load_img(picture, target_size=(224, 224))\n",
    "    test_image_1 = image_utils.img_to_array(test_image_1)\n",
    "    test_image_1 = np.expand_dims(test_image_1, axis=0)\n",
    "    test_image_1 = test_image_1/255\n",
    "    new=model.predict(test_image_1)\n",
    "    new=np.argmax(new)\n",
    "    test_.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image as image_utils\n",
    "test_answer=[]\n",
    "result_csv=pd.read_csv('img-submission.csv')\n",
    "for data_real in result_csv['id']:\n",
    "    test_answer.append('//data/examples/may_the_4_be_with_u/where_am_i/testset/'+data_real+'.jpg')\n",
    "test_=[]\n",
    "for picture in test_answer:\n",
    "    test_image_1 = image_utils.load_img(picture, target_size=(224, 224))\n",
    "    test_image_1 = image_utils.img_to_array(test_image_1)\n",
    "    test_image_1 = np.expand_dims(test_image_1, axis=0)\n",
    "    test_image_1 = test_image_1/255\n",
    "    new=model.predict(test_image_1)\n",
    "    new=np.argmax(new)\n",
    "    test_.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('image_0001.jpg')\n",
    "type(image)\n",
    "test_image_1 = image_utils.load_img(picture)\n",
    "test_image_1 = image_utils.img_to_array(test_image_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 330, 3)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13 1\n",
    "8 0\n",
    "10 8\n",
    "7 3\n",
    "9 5\n",
    "11 6\n",
    "0 9\n",
    "1 7\n",
    "5 14\n",
    "3 10\n",
    "2 12\n",
    "14 13\n",
    "6 2\n",
    "4 4\n",
    "12 11"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
